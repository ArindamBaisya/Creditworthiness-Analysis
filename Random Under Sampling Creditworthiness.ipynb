{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modeling Creditworthiness of Customers via Rare Event Phenomenon modeling using Random Under Sampling techniques and calculation of \"Loss Function\" to minimize Dollar Loss for banks, simultanously ensuring fair credit evaluation for customers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem Statement:  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Credit Evaluation is a problem which requires special techniques as it poses a number of unique challenges to the modeller and to the bank. </b>\n",
    "1. Law requires a bank to inform the customer the reason, if denied credit. This automatically limits the types of modelling techniques that can be deployed by the modeler. Specifically, \"black-box\" techniques like Neural Network should be avoided to ensure the required level of determinism and fairness.\n",
    "\n",
    "2. Credit evaluation falls under the realm of \"Rare Event Phenomenon\". Vast majority of people who apply for credit will probably receive credit from a bank and only a small fraction will not. In such situations, a model tends to predict everything as \"good credit\", which results in \"Low Error Rate\" (since bad credit are a rare event.), but completely defeats the purpose of credit evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Solution: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We tackle this two-fold problem by:</b>\n",
    "1. Using Deterministic modeling techniques like Logistic Regression which meet the requirement of fairness\n",
    "2. Devising a \"Loss Function\" which calculates the Dollar Value of Loss and uses this function as a benchmark for performance\n",
    "3. Using Random Undersampling with 10 fold Cross Validation on the Loss function to optimize decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>About the Dataset </b>\n",
    "The Dataset was provided by Prof Edward Jones, Executive Professor, Department of Statistics at Texas A&M University, College Station as a part of Academic work for course STAT 656. \n",
    "The Dataset consists of 10500 unique data points and 19 attributes and 1 target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Summary</h3>\n",
    "\n",
    "1. age : Age in years ranging from 19 to 120 \n",
    "2. amount : Credit amount any value from zero to 20,000\n",
    "3. duration: Interval Loan duration: 1 to 72 months \n",
    "4. checking: Existing status of checking account: 1, 2, 3 or 4 \n",
    "5. coapp: Status of other debtors/guarantors: 1, 2 or 3 \n",
    "6. depends: Dependents 1 (none) or 2(1 or more)\n",
    "7. employed: Employment duration status: 1, 2, 3, 4 or 5\n",
    "8. existcr: Number of existing bank loans: 1, 2, 3 or 4\n",
    "9. foreign: Foreign worker: 1 (yes) or 2 (no)\n",
    "10. history: Credit history: 0, 1, 2, 3 or 4\n",
    "11. housing: Housing status: 1, 2, or 3\n",
    "12. installp: Installment rate as percent of income: 1, 2, 3 or 4\n",
    "13. job: Employment status: 1, 2, 3 or 4\n",
    "14. marital: Status and gender: 1, 2, 3 or 4\n",
    "15. other: Other installment plans: 1, 2 or 3\n",
    "16. property: Property\townership: 1, 2, 3 or 4\n",
    "17. resident: Permanent residence status: 1, 2, 3 or 4\n",
    "18. savings: Savings account status: 1, 2, 3, 4 or 5\n",
    "19. telephon: 1(no registered phone) or 2(registered phone)\n",
    "20. good_bad: Credit rating: ‘bad’ or ‘good’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <u> Table of Contents </u></h3>\n",
    "<p> </p>\n",
    "\n",
    "\n",
    "1. Reading the Dataset, Data Replacement, Preprocessing and Imputation\n",
    "2. Modeling without Undersampling and resultant Loss\n",
    "3. 10 fold Cross Validation with different Undersampling Ratios\n",
    "4. Final Model Selection, Loss, Model Metrics and conclusion\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Reading the Dataset, Data Replacement, Preprocessing and Imputation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from AdvancedAnalytics import ReplaceImputeEncode, logreg, calculate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "df = pd.read_excel('CreditData_RareEvent.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good_bad</th>\n",
       "      <th>age</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>checking</th>\n",
       "      <th>coapp</th>\n",
       "      <th>depends</th>\n",
       "      <th>employed</th>\n",
       "      <th>existcr</th>\n",
       "      <th>foreign</th>\n",
       "      <th>history</th>\n",
       "      <th>housing</th>\n",
       "      <th>installp</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>other</th>\n",
       "      <th>property</th>\n",
       "      <th>resident</th>\n",
       "      <th>savings</th>\n",
       "      <th>telephon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>67</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>67</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>67</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>67</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>67</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  good_bad  age  amount  duration  checking  coapp  depends  employed  \\\n",
       "0     good   67    1169         6         1      1        1         5   \n",
       "1     good   67    1169         6         1      1        1         5   \n",
       "2     good   67    1169         6         1      1        1         5   \n",
       "3     good   67    1169         6         1      1        1         5   \n",
       "4     good   67    1169         6         1      1        1         5   \n",
       "\n",
       "   existcr  foreign  history  housing  installp  job  marital  other  \\\n",
       "0        2        1        4        2         4    3        3      3   \n",
       "1        2        1        4        2         4    3        3      3   \n",
       "2        2        1        4        2         4    3        3      3   \n",
       "3        2        1        4        2         4    3        3      3   \n",
       "4        2        1        4        2         4    3        3      3   \n",
       "\n",
       "   property  resident  savings  telephon  \n",
       "0         1         4        5         2  \n",
       "1         1         4        5         2  \n",
       "2         1         4        5         2  \n",
       "3         1         4        5         2  \n",
       "4         1         4        5         2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good_bad</th>\n",
       "      <th>age</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>checking</th>\n",
       "      <th>coapp</th>\n",
       "      <th>depends</th>\n",
       "      <th>employed</th>\n",
       "      <th>existcr</th>\n",
       "      <th>foreign</th>\n",
       "      <th>history</th>\n",
       "      <th>housing</th>\n",
       "      <th>installp</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>other</th>\n",
       "      <th>property</th>\n",
       "      <th>resident</th>\n",
       "      <th>savings</th>\n",
       "      <th>telephon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>bad</td>\n",
       "      <td>49</td>\n",
       "      <td>8386</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>bad</td>\n",
       "      <td>33</td>\n",
       "      <td>4844</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>bad</td>\n",
       "      <td>33</td>\n",
       "      <td>4844</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>bad</td>\n",
       "      <td>26</td>\n",
       "      <td>8229</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>bad</td>\n",
       "      <td>26</td>\n",
       "      <td>8229</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      good_bad  age  amount  duration  checking  coapp  depends  employed  \\\n",
       "10495      bad   49    8386        30         2      1        1         4   \n",
       "10496      bad   33    4844        48         4      1        1         1   \n",
       "10497      bad   33    4844        48         4      1        1         1   \n",
       "10498      bad   26    8229        36         1      1        2         3   \n",
       "10499      bad   26    8229        36         1      1        2         3   \n",
       "\n",
       "       existcr  foreign  history  housing  installp  job  marital  other  \\\n",
       "10495        1        1        4        2         2    3        3      3   \n",
       "10496        1        1        2        1         3    4        3      1   \n",
       "10497        1        1        2        1         3    4        3      1   \n",
       "10498        1        1        2        2         2    3        3      3   \n",
       "10499        1        1        2        2         2    3        3      3   \n",
       "\n",
       "       property  resident  savings  telephon  \n",
       "10495         2         2        1         1  \n",
       "10496         3         2        1         2  \n",
       "10497         3         2        1         2  \n",
       "10498         2         2        1         1  \n",
       "10499         2         2        1         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for existence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good_bad    0\n",
       "age         0\n",
       "amount      0\n",
       "duration    0\n",
       "checking    0\n",
       "coapp       0\n",
       "depends     0\n",
       "employed    0\n",
       "existcr     0\n",
       "foreign     0\n",
       "history     0\n",
       "housing     0\n",
       "installp    0\n",
       "job         0\n",
       "marital     0\n",
       "other       0\n",
       "property    0\n",
       "resident    0\n",
       "savings     0\n",
       "telephon    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no missing values we can safely proceed. The next step is to create a Data Dictionary of the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_map = {\n",
    "        'good_bad':['B',('good','bad')],\n",
    "        'age':['I', (19, 120)],\n",
    "        'amount':['I', (0, 20000)],\n",
    "        'duration':['I',(1,72)],\n",
    "        'checking':['N',(1,2,3,4)],\n",
    "        'coapp':['N',(1,2,3)],\n",
    "        'depends':['B',(1,2)],\n",
    "        'employed':['N',(1,2,3,4,5)],\n",
    "        'existcr':['N', (1,2,3,4)],\n",
    "        'foreign':['B', (1,2)],\n",
    "        'history':['N',(0,1,2,3,4)],\n",
    "        'housing':['N',(1,2,3)],\n",
    "        'installp':['N',(1,2,3,4)],\n",
    "        'job':['N',(1,2,3,4)],\n",
    "        'marital':['N', (1,2,3,4)],\n",
    "        'other':['N',(1,2,3)],\n",
    "        'property':['N',(1,2,3,4)],\n",
    "        'resident':['N',(1,2,3,4)],\n",
    "        'savings':['N',(1,2,3,4,5)],\n",
    "        'telephon':['B',(1,2)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move ahead to scale the data and us one hot encoding to encode the nominal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arindam Baisya\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Arindam Baisya\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Arindam Baisya\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Arindam Baisya\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rie=ReplaceImputeEncode(data_map=attribute_map, nominal_encoding='one-hot',interval_scale='std', drop=True, display=False)\n",
    "encoded_df = rie.fit_transform(df)\n",
    "y = np.asarray(encoded_df['good_bad'])\n",
    "X = np.asarray(encoded_df.drop('good_bad',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Modeling without Undersampling and resultant Loss </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is is to model the raw data before using Undersampling techniques to really understand how the model would have performed without any undersampling operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Errors are thrown as we attempt to change the default \"solver\" to \"lbfgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_cost = np.array(df['amount'])\n",
    "fn_cost = np.array(0.15*df['amount'])\n",
    "c_list = [1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 3, 1e+64]\n",
    "best_c = 0\n",
    "max_f = 0\n",
    "for c in c_list:\n",
    "    lgr = LogisticRegression(C=c, tol=1e-16)\n",
    "    lgr_10 = cross_val_score(lgr, X, y, scoring='f1', cv=10)\n",
    "    mean = lgr_10.mean()\n",
    "    if mean > max_f:\n",
    "        max_f = mean\n",
    "        best_c = c\n",
    "        best_lgr = lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model using Entire Dataset and C =  1\n",
      "\n",
      "Model Metrics\n",
      "Observations...............     10500\n",
      "Coefficients...............        46\n",
      "DF Error...................     10454\n",
      "Mean Absolute Error........    0.0785\n",
      "Avg Squared Error..........    0.0379\n",
      "Accuracy...................    0.9556\n",
      "Precision..................    0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arindam Baisya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (Sensitivity).......    1.0000\n",
      "F1-Score...................    0.9772\n",
      "MISC (Misclassification)...      4.4%\n",
      "     class 0...............     93.2%\n",
      "     class 1...............      0.0%\n",
      "\n",
      "\n",
      "     Confusion\n",
      "       Matrix     Class 0   Class 1  \n",
      "Class 0.....        34       466\n",
      "Class 1.....         0     10000\n",
      "Misclassification Rate.    0.0444\n",
      "False Negative Loss....         0\n",
      "False Positive Loss....   1800209\n",
      "Total Loss.............   1800209\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogistic Regression Model using Entire Dataset and C = \",best_c)\n",
    "best_lgr.fit(X,y)\n",
    "logreg.display_binary_metrics(best_lgr, X, y)\n",
    "loss,conf_mat = calculate.binary_loss(y,best_lgr.predict(X),fp_cost,fn_cost)\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**16 - 1\n",
    "rand_val = np.random.randint(1, high=max_seed, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. 10 fold Cross Validation with different Undersampling Ratios </h3>\n",
    "\n",
    "<p> </p>\n",
    "We now use different Undersamping Ratios with 10 fold CV to find the optimum result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model using 50:50 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.2812\n",
      "False Negative Loss.... $ 2,321,172\n",
      "False Positive Loss.... $   426,837\n",
      "Total Loss............. $ 2,748,009 +/- $9,764\n",
      "Best C.................    1.00E-03\n",
      "Misclassification Rate.      0.2773\n",
      "False Negative Loss.... $ 2,243,899\n",
      "False Positive Loss.... $   394,464\n",
      "Total Loss............. $ 2,638,362 +/- $11,396\n",
      "Best C.................    1.00E-02\n",
      "Misclassification Rate.      0.2872\n",
      "False Negative Loss.... $ 2,069,123\n",
      "False Positive Loss.... $   334,044\n",
      "Total Loss............. $ 2,403,166 +/- $12,108\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.2798\n",
      "False Negative Loss.... $ 1,764,709\n",
      "False Positive Loss.... $   335,186\n",
      "Total Loss............. $ 2,099,894 +/- $20,415\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.2688\n",
      "False Negative Loss.... $ 1,566,610\n",
      "False Positive Loss.... $   341,934\n",
      "Total Loss............. $ 1,908,545 +/- $16,453\n",
      "Best C.................    2.00E+00\n",
      "Misclassification Rate.      0.2684\n",
      "False Negative Loss.... $ 1,552,028\n",
      "False Positive Loss.... $   354,143\n",
      "Total Loss............. $ 1,906,171 +/- $16,194\n",
      "Best C.................    3.00E+00\n",
      "Misclassification Rate.      0.2685\n",
      "False Negative Loss.... $ 1,550,687\n",
      "False Positive Loss.... $   351,641\n",
      "Total Loss............. $ 1,902,328 +/- $16,330\n",
      "Best C.................    4.00E+00\n",
      "Misclassification Rate.      0.2689\n",
      "False Negative Loss.... $ 1,550,525\n",
      "False Positive Loss.... $   351,636\n",
      "Total Loss............. $ 1,902,161 +/- $15,961\n",
      "Best C.................    4.00E+00\n",
      "Misclassification Rate.      0.2689\n",
      "False Negative Loss.... $ 1,550,525\n",
      "False Positive Loss.... $   351,636\n",
      "Total Loss............. $ 1,902,161 +/- $15,961\n",
      "\n",
      "Best RUS Ratio.........       50:50\n",
      "Best C.................    4.00E+00\n",
      "Lowest Loss............ $ 1,902,161 +/- $15,961\n",
      "\n",
      "Logistic Regression Model using 60:40 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-03\n",
      "Misclassification Rate.      0.0598\n",
      "False Negative Loss.... $   299,393\n",
      "False Positive Loss.... $ 1,560,367\n",
      "Total Loss............. $ 1,859,760 +/- $9,723\n",
      "Best C.................    1.00E-02\n",
      "Misclassification Rate.      0.1412\n",
      "False Negative Loss.... $ 1,105,190\n",
      "False Positive Loss.... $   738,298\n",
      "Total Loss............. $ 1,843,488 +/- $11,146\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.1756\n",
      "False Negative Loss.... $ 1,128,267\n",
      "False Positive Loss.... $   551,114\n",
      "Total Loss............. $ 1,679,381 +/- $13,792\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.1840\n",
      "False Negative Loss.... $ 1,112,557\n",
      "False Positive Loss.... $   538,464\n",
      "Total Loss............. $ 1,651,020 +/- $12,511\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.1840\n",
      "False Negative Loss.... $ 1,112,557\n",
      "False Positive Loss.... $   538,464\n",
      "Total Loss............. $ 1,651,020 +/- $12,511\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.1840\n",
      "False Negative Loss.... $ 1,112,557\n",
      "False Positive Loss.... $   538,464\n",
      "Total Loss............. $ 1,651,020 +/- $12,511\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.1840\n",
      "False Negative Loss.... $ 1,112,557\n",
      "False Positive Loss.... $   538,464\n",
      "Total Loss............. $ 1,651,020 +/- $12,511\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.1840\n",
      "False Negative Loss.... $ 1,112,557\n",
      "False Positive Loss.... $   538,464\n",
      "Total Loss............. $ 1,651,020 +/- $12,511\n",
      "\n",
      "Best RUS Ratio.........       60:40\n",
      "Best C.................    1.00E+00\n",
      "Lowest Loss............ $ 1,651,020 +/- $12,511\n",
      "\n",
      "Logistic Regression Model using 70:30 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-03\n",
      "Misclassification Rate.      0.0474\n",
      "False Negative Loss.... $     1,291\n",
      "False Positive Loss.... $ 2,043,258\n",
      "Total Loss............. $ 2,044,549 +/- $2,713\n",
      "Best C.................    1.00E-02\n",
      "Misclassification Rate.      0.0688\n",
      "False Negative Loss.... $   380,616\n",
      "False Positive Loss.... $ 1,320,854\n",
      "Total Loss............. $ 1,701,469 +/- $13,887\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.1067\n",
      "False Negative Loss.... $   625,154\n",
      "False Positive Loss.... $   845,761\n",
      "Total Loss............. $ 1,470,914 +/- $11,984\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.1067\n",
      "False Negative Loss.... $   625,154\n",
      "False Positive Loss.... $   845,761\n",
      "Total Loss............. $ 1,470,914 +/- $11,984\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.1067\n",
      "False Negative Loss.... $   625,154\n",
      "False Positive Loss.... $   845,761\n",
      "Total Loss............. $ 1,470,914 +/- $11,984\n",
      "Best C.................    3.00E+00\n",
      "Misclassification Rate.      0.1270\n",
      "False Negative Loss.... $   722,488\n",
      "False Positive Loss.... $   747,107\n",
      "Total Loss............. $ 1,469,595 +/- $12,993\n",
      "Best C.................    3.00E+00\n",
      "Misclassification Rate.      0.1270\n",
      "False Negative Loss.... $   722,488\n",
      "False Positive Loss.... $   747,107\n",
      "Total Loss............. $ 1,469,595 +/- $12,993\n",
      "Best C.................    3.00E+00\n",
      "Misclassification Rate.      0.1270\n",
      "False Negative Loss.... $   722,488\n",
      "False Positive Loss.... $   747,107\n",
      "Total Loss............. $ 1,469,595 +/- $12,993\n",
      "\n",
      "Best RUS Ratio.........       70:30\n",
      "Best C.................    3.00E+00\n",
      "Lowest Loss............ $ 1,469,595 +/- $12,993\n",
      "\n",
      "Logistic Regression Model using 80:20 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-02\n",
      "Misclassification Rate.      0.0466\n",
      "False Negative Loss.... $    47,491\n",
      "False Positive Loss.... $ 1,723,747\n",
      "Total Loss............. $ 1,771,238 +/- $8,770\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.0595\n",
      "False Negative Loss.... $   221,584\n",
      "False Positive Loss.... $ 1,235,614\n",
      "Total Loss............. $ 1,457,198 +/- $5,450\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.0721\n",
      "False Negative Loss.... $   321,087\n",
      "False Positive Loss.... $ 1,031,851\n",
      "Total Loss............. $ 1,352,938 +/- $9,802\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.0721\n",
      "False Negative Loss.... $   321,087\n",
      "False Positive Loss.... $ 1,031,851\n",
      "Total Loss............. $ 1,352,938 +/- $9,802\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.0721\n",
      "False Negative Loss.... $   321,087\n",
      "False Positive Loss.... $ 1,031,851\n",
      "Total Loss............. $ 1,352,938 +/- $9,802\n",
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.0721\n",
      "False Negative Loss.... $   321,087\n",
      "False Positive Loss.... $ 1,031,851\n",
      "Total Loss............. $ 1,352,938 +/- $9,802\n",
      "Best C.................    1.00E+64\n",
      "Misclassification Rate.      0.0775\n",
      "False Negative Loss.... $   361,964\n",
      "False Positive Loss.... $   990,162\n",
      "Total Loss............. $ 1,352,127 +/- $10,609\n",
      "\n",
      "Best RUS Ratio.........       80:20\n",
      "Best C.................    1.00E+64\n",
      "Lowest Loss............ $ 1,352,127 +/- $10,609\n",
      "\n",
      "Logistic Regression Model using 90:10 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0476\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,096,550\n",
      "Total Loss............. $ 2,096,550 +/- $0\n",
      "Best C.................    1.00E-02\n",
      "Misclassification Rate.      0.0472\n",
      "False Negative Loss.... $         0\n",
      "False Positive Loss.... $ 2,023,738\n",
      "Total Loss............. $ 2,023,738 +/- $3,548\n",
      "Best C.................    1.00E-01\n",
      "Misclassification Rate.      0.0444\n",
      "False Negative Loss.... $    35,225\n",
      "False Positive Loss.... $ 1,662,787\n",
      "Total Loss............. $ 1,698,013 +/- $7,021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C.................    1.00E+00\n",
      "Misclassification Rate.      0.0443\n",
      "False Negative Loss.... $    76,843\n",
      "False Positive Loss.... $ 1,478,691\n",
      "Total Loss............. $ 1,555,533 +/- $5,191\n",
      "Best C.................    2.00E+00\n",
      "Misclassification Rate.      0.0441\n",
      "False Negative Loss.... $    79,736\n",
      "False Positive Loss.... $ 1,455,712\n",
      "Total Loss............. $ 1,535,448 +/- $3,599\n",
      "Best C.................    3.00E+00\n",
      "Misclassification Rate.      0.0440\n",
      "False Negative Loss.... $    80,524\n",
      "False Positive Loss.... $ 1,447,921\n",
      "Total Loss............. $ 1,528,444 +/- $4,144\n",
      "Best C.................    4.00E+00\n",
      "Misclassification Rate.      0.0439\n",
      "False Negative Loss.... $    80,524\n",
      "False Positive Loss.... $ 1,440,888\n",
      "Total Loss............. $ 1,521,412 +/- $4,952\n",
      "Best C.................    1.00E+64\n",
      "Misclassification Rate.      0.0439\n",
      "False Negative Loss.... $    85,380\n",
      "False Positive Loss.... $ 1,420,117\n",
      "Total Loss............. $ 1,505,497 +/- $5,181\n",
      "\n",
      "Best RUS Ratio.........       80:20\n",
      "Best C.................    1.00E+64\n",
      "Lowest Loss............ $ 1,352,127 +/- $10,609\n"
     ]
    }
   ],
   "source": [
    "ratio = [ '50:50', '60:40', '70:30', '80:20', '90:10' ]\n",
    "\n",
    "rus_ratio = ({0:500, 1:500}, {0:500, 1:750}, {0:500, 1:1167},{0:500, 1:2000}, {0:500, 1:4500})\n",
    "c_list = [1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 3, 4, 1e+64]\n",
    "min_loss = 1e64\n",
    "best_ratio = 0\n",
    "for k in range(len(rus_ratio)):\n",
    "    print(\"\\nLogistic Regression Model using \" + ratio[k] + \" RUS\")\n",
    "    best_c = 0\n",
    "    min_loss_c = 1e64\n",
    "    for j in range(len(c_list)):\n",
    "        c = c_list[j]\n",
    "        fn_loss = np.zeros(len(rand_val))\n",
    "        fp_loss = np.zeros(len(rand_val))\n",
    "        misc = np.zeros(len(rand_val))\n",
    "        for i in range(len(rand_val)):\n",
    "            rus = RandomUnderSampler(ratio=rus_ratio[k],random_state=rand_val[i],return_indices=False,replacement=False)\n",
    "            X_rus, y_rus = rus.fit_sample(X, y)\n",
    "            lgr = LogisticRegression(C=c, tol=1e-16, solver='lbfgs',max_iter=1000)\n",
    "            lgr.fit(X_rus, y_rus)\n",
    "            loss, conf_mat = calculate.binary_loss(y, lgr.predict(X),fp_cost, fn_cost, display=False)\n",
    "            fn_loss[i] = loss[0]\n",
    "            fp_loss[i] = loss[1]\n",
    "            misc[i] = (conf_mat[1] + conf_mat[2])/y.shape[0]\n",
    "        avg_misc = np.average(misc)\n",
    "        t_loss = fp_loss+fn_loss\n",
    "        avg_loss = np.average(t_loss)\n",
    "        if avg_loss < min_loss_c:\n",
    "            min_loss_c = avg_loss\n",
    "            se_loss_c = np.std(t_loss)/math.sqrt(len(rand_val))\n",
    "            best_c = c\n",
    "            misc_c = avg_misc\n",
    "            fn_avg_loss = np.average(fn_loss)\n",
    "            fp_avg_loss = np.average(fp_loss)\n",
    "        if min_loss_c < min_loss:\n",
    "            min_loss = min_loss_c\n",
    "            se_loss = se_loss_c\n",
    "            best_ratio = k\n",
    "            best_reg = best_c\n",
    "        print(\"{:.<23s}{:12.2E}\".format(\"Best C\", best_c))\n",
    "        print(\"{:.<23s}{:12.4f}\".format(\"Misclassification Rate\",misc_c))\n",
    "        print(\"{:.<23s} ${:10,.0f}\".format(\"False Negative Loss\",fn_avg_loss))\n",
    "        print(\"{:.<23s} ${:10,.0f}\".format(\"False Positive Loss\",fp_avg_loss))\n",
    "        print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Total Loss\", min_loss_c, \" +/- \", se_loss_c))\n",
    "    print(\"\")\n",
    "    print(\"{:.<23s}{:>12s}\".format(\"Best RUS Ratio\", ratio[best_ratio]))\n",
    "    print(\"{:.<23s}{:12.2E}\".format(\"Best C\", best_reg))\n",
    "    print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Lowest Loss\", min_loss, \" +/-\", se_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_obs = len(y)\n",
    "n_rand = 100\n",
    "predicted_prob = np.zeros((n_obs,n_rand))\n",
    "avg_prob = np.zeros(n_obs)\n",
    "# Setup 100 random number seeds for use in creating random samples\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**16 - 1\n",
    "rand_value = np.random.randint(1, high=max_seed, size=n_rand)\n",
    "# Model 100 random samples, each with a 70:30 ratio\n",
    "for i in range(len(rand_value)):\n",
    "    rus = RandomUnderSampler(ratio=rus_ratio[best_ratio],random_state=rand_value[i], return_indices=False, replacement=False)\n",
    "    X_rus, y_rus = rus.fit_sample(X, y)\n",
    "    lgr = LogisticRegression(C=best_c, tol=1e-16, solver='lbfgs', max_iter=1000)\n",
    "    lgr.fit(X_rus, y_rus)\n",
    "    predicted_prob[0:n_obs, i] = lgr.predict_proba(X)[0:n_obs, 0]\n",
    "for i in range(n_obs):\n",
    "    avg_prob[i] = np.mean(predicted_prob[i,0:n_rand])\n",
    "# Set y_pred equal to the predicted classification\n",
    "y_pred = avg_prob[0:n_obs] < 0.5\n",
    "y_pred.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. Final Model Selection, Loss, Model Metrics and conclusion </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Estimates based on averaging 100 Models in $s\n",
      "Misclassification Rate.    0.0773\n",
      "False Negative Loss....    375762\n",
      "False Positive Loss....   1052394\n",
      "Total Loss.............   1428156\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss from using the ensemble predictions\n",
    "print(\"\\nEnsemble Estimates based on averaging\",len(rand_value), \"Models in $s\")\n",
    "loss, conf_mat = calculate.binary_loss(y, y_pred, fp_cost, fn_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conclusion </h3>\n",
    "<p> </p>\n",
    "\n",
    "We successfully modified the model and reduced the initial Loss of USD1.8 million to USD1.438 million.\n",
    "<p> </p>\n",
    "\n",
    "Techniques employed:\n",
    "1. Random Undersampling\n",
    "2. 10 fold CV\n",
    "3. Modified Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
